{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building paragraph vectors using Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import common text corpus, Doc2Vec algorithm and Tagged Document functionality from Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.5.0)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus on which training will happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Tagged Documents from the corpus as that's an expectation from the Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
       " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
       " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
       " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
       " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
       " TaggedDocument(words=['trees'], tags=[5]),\n",
       " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
       " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
       " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a basic Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the vector size (should be 5 as we specified it on top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many document vectors did we train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-c8c8dc9618a3>:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  len(model.docvecs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.docvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the vocabulary information for the model we built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 0,\n",
       " 'graph': 1,\n",
       " 'trees': 2,\n",
       " 'user': 3,\n",
       " 'minors': 4,\n",
       " 'eps': 5,\n",
       " 'time': 6,\n",
       " 'response': 7,\n",
       " 'survey': 8,\n",
       " 'computer': 9,\n",
       " 'interface': 10,\n",
       " 'human': 11}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's infer a vector based on the trained Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03756111 -0.03715252  0.0129479   0.02861738  0.08362415]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a new model changing vector size and minimum count eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=3, workers=4)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 0, 'graph': 1, 'trees': 2, 'user': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0371801  -0.03677846  0.01317028  0.02929444  0.08339311]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec built next would be based on the distributed memory model (dm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=1)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00453587 -0.00391252  0.00089709  0.00296409  0.00813381  0.00256962\n",
      "  0.00136201  0.00242808 -0.00329857  0.00952082 -0.0017757   0.00799976\n",
      "  0.00059354 -0.00814846  0.00873208 -0.00364986  0.00074912  0.0027355\n",
      "  0.00131337  0.00229351 -0.00573052  0.0051463   0.00388442 -0.00533876\n",
      "  0.00435362 -0.0018584   0.00395117 -0.00281297 -0.00025203  0.0020558\n",
      " -0.00932153 -0.00561514 -0.00431304 -0.00056523  0.00643483 -0.00356581\n",
      " -0.00962584 -0.00659742 -0.00779687 -0.0017348  -0.00125581  0.00776353\n",
      "  0.00157168  0.00380536  0.00258829 -0.00814661 -0.00045274  0.00371402\n",
      " -0.00660128  0.00900414]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec built next would be based on the distributed bag of words approach (dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, dm=0)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00593539 -0.00425362  0.0004662   0.0026706   0.00770862  0.00273647\n",
      "  0.00091485  0.00346302 -0.0038242   0.01032096 -0.00157123  0.00881096\n",
      "  0.00088869 -0.00865343  0.00962424 -0.00427841 -0.00027584  0.00275743\n",
      "  0.00066734  0.00265018 -0.00622919  0.00510398  0.0032966  -0.0051358\n",
      "  0.00394173 -0.00155933  0.00362163 -0.00380825 -0.00030596  0.00192817\n",
      " -0.00831099 -0.00475652 -0.00538212 -0.00015652  0.00611886 -0.00251408\n",
      " -0.01026612 -0.00722642 -0.00749515 -0.00213776 -0.00172963  0.00873332\n",
      "  0.00148657  0.00294841  0.0013323  -0.00739662  0.00019065  0.00405663\n",
      " -0.00620056  0.00857089]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the window size which controls the maximum distance between current and predicted word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=0)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.85619686e-03 -4.14020661e-03  2.92560144e-04  2.62079341e-03\n",
      "  7.67338788e-03  2.98890611e-03  8.56717757e-04  3.49160237e-03\n",
      " -3.95824527e-03  1.03212604e-02 -1.36668689e-03  8.95858556e-03\n",
      "  1.07341912e-03 -8.61879252e-03  9.46658943e-03 -4.40538721e-03\n",
      "  7.55539877e-05  2.91305920e-03  6.73631148e-04  2.50865007e-03\n",
      " -6.35773549e-03  5.19524980e-03  3.12256394e-03 -5.28495573e-03\n",
      "  4.08078264e-03 -1.63315982e-03  3.49024963e-03 -3.97459324e-03\n",
      " -2.50483339e-04  1.84055394e-03 -8.26205779e-03 -4.62255860e-03\n",
      " -5.55908680e-03 -2.01697883e-04  6.21228153e-03 -2.48296838e-03\n",
      " -1.01173725e-02 -7.28166755e-03 -7.46667059e-03 -1.95274758e-03\n",
      " -2.01439532e-03  8.60384945e-03  1.23042718e-03  2.98013189e-03\n",
      "  1.52203394e-03 -7.30147678e-03  1.30460947e-04  3.87898064e-03\n",
      " -5.91142336e-03  8.69590230e-03]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding initial learning rate and to what value should the learning rate drop to linearly over training (alpha and min_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31974137 -0.06716121 -0.20223242 -0.00366339 -0.12749013  0.12073709\n",
      " -0.16609545  0.18861233 -0.27778292  0.12815428  0.23538662  0.27723283\n",
      "  0.11906813 -0.25756946  0.18341936 -0.352204   -0.08047464  0.13784613\n",
      " -0.3398532  -0.03839013 -0.07702577  0.07554863 -0.16768833  0.1620395\n",
      " -0.04139753 -0.00550529 -0.20810111 -0.29029062  0.05777445 -0.18847813\n",
      "  0.32191885  0.21942474 -0.3537838  -0.07794843 -0.08159574  0.17768037\n",
      " -0.03486383 -0.1888445  -0.03092271 -0.01426172 -0.12569518  0.15150201\n",
      "  0.00671369 -0.31110078 -0.0699418   0.15969911  0.18711855 -0.00819251\n",
      "  0.23305197 -0.16736859]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dm_concat parameter to use concatenation of the word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, alpha=0.3, min_alpha=0.05, dm_concat=1)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04073207 -0.20443733 -0.11139946  0.01324134  0.16146013  0.07265161\n",
      "  0.02887594 -0.2575949   0.00560988  0.1745744  -0.10879918 -0.0027538\n",
      " -0.1769514  -0.17444625 -0.00454347 -0.1584279   0.04258839  0.08098657\n",
      " -0.04190582 -0.19145466  0.00216675  0.02538604 -0.08776652  0.02294124\n",
      " -0.23279321 -0.08641739 -0.2657417  -0.01555547  0.0756209  -0.16681834\n",
      "  0.16999461 -0.03340479  0.05899809 -0.20745786  0.10253324 -0.15544245\n",
      "  0.05034002 -0.11959898 -0.01451971  0.03602321  0.20438002 -0.01023639\n",
      "  0.2261081  -0.21462099  0.05096089 -0.08346988  0.04929426 -0.00307659\n",
      "  0.00197548 -0.14021483]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dm_mean parameter to use sum of the context word vectors (dm_mean=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, dm_concat=0, dm_mean=1, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31974137 -0.06716121 -0.20223242 -0.00366339 -0.12749013  0.12073709\n",
      " -0.16609545  0.18861233 -0.27778292  0.12815428  0.23538662  0.27723283\n",
      "  0.11906813 -0.25756946  0.18341936 -0.352204   -0.08047464  0.13784613\n",
      " -0.3398532  -0.03839013 -0.07702577  0.07554863 -0.16768833  0.1620395\n",
      " -0.04139753 -0.00550529 -0.20810111 -0.29029062  0.05777445 -0.18847813\n",
      "  0.32191885  0.21942474 -0.3537838  -0.07794843 -0.08159574  0.17768037\n",
      " -0.03486383 -0.1888445  -0.03092271 -0.01426172 -0.12569518  0.15150201\n",
      "  0.00671369 -0.31110078 -0.0699418   0.15969911  0.18711855 -0.00819251\n",
      "  0.23305197 -0.16736859]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dm_mean parameter to use mean of the context word vectors (dm_mean=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=50, min_count=2, epochs=40, window=2, dm=1, dm_concat=0, dm_mean=0, alpha=0.3, min_alpha=0.05)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31974137 -0.06716121 -0.20223242 -0.00366339 -0.12749013  0.12073709\n",
      " -0.16609545  0.18861233 -0.27778292  0.12815428  0.23538662  0.27723283\n",
      "  0.11906813 -0.25756946  0.18341936 -0.352204   -0.08047464  0.13784613\n",
      " -0.3398532  -0.03839013 -0.07702577  0.07554863 -0.16768833  0.1620395\n",
      " -0.04139753 -0.00550529 -0.20810111 -0.29029062  0.05777445 -0.18847813\n",
      "  0.32191885  0.21942474 -0.3537838  -0.07794843 -0.08159574  0.17768037\n",
      " -0.03486383 -0.1888445  -0.03092271 -0.01426172 -0.12569518  0.15150201\n",
      "  0.00671369 -0.31110078 -0.0699418   0.15969911  0.18711855 -0.00819251\n",
      "  0.23305197 -0.16736859]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['user', 'interface', 'for', 'computer'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
